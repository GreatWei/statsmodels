# DO NOT EDIT
# Autogenerated from the notebook discrete_choice_example.ipynb.
# Edit the notebook and then sync the output with this file.
#
# flake8: noqa
# DO NOT EDIT

#!/usr/bin/env python
# coding: utf-8

# # 离散选择模型

# ## 博览会的事务数据

# 《红皮书》于1974年对女性进行了一次调查，询问婚外情。

import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.formula.api import logit

print(sm.datasets.fair.SOURCE)

print(sm.datasets.fair.NOTE)

dta = sm.datasets.fair.load_pandas().data

dta['affair'] = (dta['affairs'] > 0).astype(float)
print(dta.head(10))

print(dta.describe())

affair_mod = logit(
    "affair ~ occupation + educ + occupation_husb"
    "+ rate_marriage + age + yrs_married + children"
    " + religious", dta).fit()

print(affair_mod.summary())

# 我们的预测如何？

affair_mod.pred_table()

# 离散选择模型的系数并不能告诉我们太多。 我们追求的是边际效应。

mfx = affair_mod.get_margeff()
print(mfx.summary())

respondent1000 = dta.iloc[1000]
print(respondent1000)

resp = dict(
    zip(
        range(1, 9), respondent1000[[
            "occupation", "educ", "occupation_husb", "rate_marriage", "age",
            "yrs_married", "children", "religious"
        ]].tolist()))
resp.update({0: 1})
print(resp)

mfx = affair_mod.get_margeff(atexog=resp)
print(mfx.summary())

# `predict` 希望得到一个 `DataFrame` 因为 `patsy` 通常选择列

respondent1000 = dta.iloc[[1000]]
affair_mod.predict(respondent1000)

affair_mod.fittedvalues[1000]

affair_mod.model.cdf(affair_mod.fittedvalues[1000])

# 这里的"correct" 模型可能是 Tobit 模型。 如果有人对审查回归模型感兴趣，我们有一个任务是促使 "tobit-model" 分支在 github 发展。

# ### 练习: Logit vs Probit

fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111)
support = np.linspace(-6, 6, 1000)
ax.plot(support, stats.logistic.cdf(support), 'r-', label='Logistic')
ax.plot(support, stats.norm.cdf(support), label='Probit')
ax.legend()

fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111)
support = np.linspace(-6, 6, 1000)
ax.plot(support, stats.logistic.pdf(support), 'r-', label='Logistic')
ax.plot(support, stats.norm.pdf(support), label='Probit')
ax.legend()

# 将上面的Logit Fair模型的估计与Probit模型进行比较。 预测表看起来更好吗？ 边际效应有何不同？

# ### 广义线性模型示例

print(sm.datasets.star98.SOURCE)

print(sm.datasets.star98.DESCRLONG)

print(sm.datasets.star98.NOTE)

dta = sm.datasets.star98.load_pandas().data
print(dta.columns)

print(dta[[
    'NABOVE', 'NBELOW', 'LOWINC', 'PERASIAN', 'PERBLACK', 'PERHISP', 'PERMINTE'
]].head(10))

print(dta[[
    'AVYRSEXP', 'AVSALK', 'PERSPENK', 'PTRATIO', 'PCTAF', 'PCTCHRT', 'PCTYRRND'
]].head(10))

formula = 'NABOVE + NBELOW ~ LOWINC + PERASIAN + PERBLACK + PERHISP + PCTCHRT '
formula += '+ PCTYRRND + PERMINTE*AVYRSEXP*AVSALK + PERSPENK*PTRATIO*PCTAF'

# #### Aside: 二项分布

# 将一个六面骰子掷5次，正好2个4的概率是多少？

stats.binom(5, 1. / 6).pmf(2)

from scipy.special import comb
comb(5, 2) * (1 / 6.)**2 * (5 / 6.)**3

from statsmodels.formula.api import glm
glm_mod = glm(formula, dta, family=sm.families.Binomial()).fit()

print(glm_mod.summary())

# 试验次数

glm_mod.model.data.orig_endog.sum(1)

glm_mod.fittedvalues * glm_mod.model.data.orig_endog.sum(1)

# 第一个差异：我们将所有解释变量保持在其均值不变，并操纵低收入家庭的百分比来评估其对响应变量的影响：

exog = glm_mod.model.data.orig_exog  # get the dataframe

means25 = exog.mean()
print(means25)

means25['LOWINC'] = exog['LOWINC'].quantile(.25)
print(means25)

means75 = exog.mean()
means75['LOWINC'] = exog['LOWINC'].quantile(.75)
print(means75)

# 再次说明, `predict` 希望得到一个 `DataFrame` 因为 `patsy` 通常选择列

resp25 = glm_mod.predict(pd.DataFrame(means25).T)
resp75 = glm_mod.predict(pd.DataFrame(means75).T)
diff = resp75 - resp25

# 低收入百分比的四分位差
  
# 学区的家庭是：

print("%2.4f%%" % (diff[0] * 100))

nobs = glm_mod.nobs
y = glm_mod.model.endog
yhat = glm_mod.mu

from statsmodels.graphics.api import abline_plot
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, ylabel='Observed Values', xlabel='Fitted Values')
ax.scatter(yhat, y)
y_vs_yhat = sm.OLS(y, sm.add_constant(yhat, prepend=True)).fit()
fig = abline_plot(model_results=y_vs_yhat, ax=ax)

# #### 绘制拟合值 vs 皮尔逊残差

# 皮尔逊残差被定义为 
#
# $$\frac{(y - \mu)}{\sqrt{(var(\mu))}}$$
#
# 然而方差通常由家庭所决定，例如，二项式方差是 $np(1 - p)$

fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111,
                     title='Residual Dependence Plot',
                     xlabel='Fitted Values',
                     ylabel='Pearson Residuals')
ax.scatter(yhat, stats.zscore(glm_mod.resid_pearson))
ax.axis('tight')
ax.plot([0.0, 1.0], [0.0, 0.0], 'k-')

# #### 具有内核密度的标准偏差残差的直方图
# 估算值重叠

# 偏差残差的定义取决于家庭。 这是二项分布：
#
# $$r_{dev} = sign\left(Y-\mu\right)*\sqrt{2n(Y\log\frac{Y}{\mu}+(1-Y)\log
# \frac{(1-Y)}{(1-\mu)}}$$
#
# 它们通常用来检验 ill-fitting 的协方差

resid = glm_mod.resid_deviance
resid_std = stats.zscore(resid)
kde_resid = sm.nonparametric.KDEUnivariate(resid_std)
kde_resid.fit()

fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, title="Standardized Deviance Residuals")
ax.hist(resid_std, bins=25, density=True)
ax.plot(kde_resid.support, kde_resid.density, 'r')

# #### 偏差残差的 QQ-图 

fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111)
fig = sm.graphics.qqplot(resid, line='r', ax=ax)
