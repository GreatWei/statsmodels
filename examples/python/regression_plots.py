# coding: utf-8

# DO NOT EDIT
# Autogenerated from the notebook regression_plots.ipynb.
# Edit the notebook and then sync the output with this file.
#
# flake8: noqa
# DO NOT EDIT

# # 回归图

from statsmodels.compat import lzip
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.formula.api import ols

# ## Duncan 的威望数据集

# ### 加载数据

# 我们可以使用一个实用函数来加载任何可用的R数据集 <a href="https://vincentarelbundock.github.io/Rdatasets/">R 数据集包</a>.

prestige = sm.datasets.get_rdataset("Duncan", "carData", cache=True).data

prestige.head()

prestige_model = ols("prestige ~ income + education", data=prestige).fit()

print(prestige_model.summary())

# ### 影响图

# 影响图显示了（外部）学生化残差与每个观察结果（通过帽子矩阵测得）的比率。
#
# 外部学生化残差是按其标准偏差缩放的残差，其中
#
# $$var(\hat{\epsilon}_i)=\hat{\sigma}^2_i(1-h_{ii})$$
#
# with
#
# $$\hat{\sigma}^2_i=\frac{1}{n - p - 1 \;\;}\sum_{j}^{n}\;\;\;\forall
# \;\;\; j \neq i$$
#
# $n$ 是观测数 $p$ 是回归数.
# $h_{ii}$ 是帽子矩阵的第 $i$-th 对角元素
#
# $$H=X(X^{\;\prime}X)^{-1}X^{\;\prime}$$
#
# 每个点的影响可以通过标准关键字参数来可视化。 选项包括 Cook 距离和 DFFITS，这是两种影响力的度量。

fig, ax = plt.subplots(figsize=(12, 8))
fig = sm.graphics.influence_plot(prestige_model, ax=ax, criterion="cooks")

# 如您所见，有一些令人担忧的观察。 承包商和记者的杠杆率均较低，但残差较大。 <br /> RR.工程师具有
# 较小的残差和较大的杠杆率。指挥官和牧师既有很高的杠杆率又有很大的残差，<br /> 因此影响很大 

# ### 偏回归图

# 由于我们正在进行多元回归，因此我们不能只看单个二元图来识别关系。 <br />相反，我们希望查看以其他自变量
# 为条件的因变量和自变量之间的关系，我们可以通过使用偏回归图（也称为添加变量图）来实现 <br />
#
# 在偏回归图中,为了辨别响应变量和第 $k$-th 变量之间的关系, 我们 <br /> 通过对响应变量与自变量（不包括 $X_k$）
# 进行回归来计算残差。我们可以用 <br /> $X_{\sim k}$ 来表示. 然后，我们通过对 $X_{\sim k}$ 回归 $X_k$ 来计算
# 残差，偏回归图是前者对后者残差的图 <br />
#
# 该图的显着点是拟合线的斜率为 $\beta_k$ ，截距为零。 此图的残差<br />与具有完整 $X$ 的原始模型的最小二乘拟合的残差相同。
# 您可以轻松地辨别<br />各个数据值对系数估计的影响。 如果 obs_labels 为 True，则这些点将使用其观察标签进行注释。 您也可以
# 看到违反基本假设，例如同方差 和<br /> 线性



fig, ax = plt.subplots(figsize=(12, 8))
fig = sm.graphics.plot_partregress(
    "prestige", "income", ["income", "education"], data=prestige, ax=ax)

fix, ax = plt.subplots(figsize=(12, 14))
fig = sm.graphics.plot_partregress(
    "prestige", "income", ["education"], data=prestige, ax=ax)

# 如您所见，偏回归图确认了指挥管、牧师和 RR.工程师对收入和声望之间的局部关系的影响。
# 这些情况大大降低了收入对声望的影响。 剔除这些情况也可以确认这一点。

subset = ~prestige.index.isin(["conductor", "RR.engineer", "minister"])
prestige_model2 = ols(
    "prestige ~ income + education", data=prestige, subset=subset).fit()
print(prestige_model2.summary())

# 要快速检查所有回归变量，可以使用 plot_partregress_grid。这些图不会标记<br />点，
# 但是您可以使用它们来识别问题，然后使用 plot_partregress 获取更多信息

fig = plt.figure(figsize=(12, 8))
fig = sm.graphics.plot_partregress_grid(prestige_model, fig=fig)

# ### Component-Component plus Residual (CCPR) Plots

# 
# CCPR 图提供了一种通过考虑其他<br />自变量的影响来判断一个回归变量对<br />响应变量的影响的方法。 偏残差图可以被定义为  <br />
# $\text{Residuals} + B_iX_i \text{ }\text{ }$ 与 $ X_i $。 该组件将$ B_iX_i $ 与 <br /> $ X_i $ 相加以显示拟合线的位置。 
# 如果 $ X_i $ <br />与任何其他自变量高度相关，则应格外小心。 如果是这种情况，则图中显示的方差将低估真实方差。


fig, ax = plt.subplots(figsize=(12, 8))
fig = sm.graphics.plot_ccpr(prestige_model, "education", ax=ax)

# 如您所见，受收入限制的教育所解释的声望变化之间的关系是线性的，尽管您可以看到一些观察结果对该关系产生了重大影响。 我们可以使用
# plot_ccpr_grid 快速查看多个变量。

fig = plt.figure(figsize=(12, 8))
fig = sm.graphics.plot_ccpr_grid(prestige_model, fig=fig)

# ### 回归图

# plot_regress_exog 函数是一个便捷的函数，它提供一个 2x2 图，其中包含因变量和具有置信区间的拟合值，所选自变量的模型残差，所选自变量
# 的偏回归图和 CCPR 图 。 此函数可用于快速检查有关单个回归变量的建模假设。

fig = plt.figure(figsize=(12, 8))
fig = sm.graphics.plot_regress_exog(prestige_model, "education", fig=fig)

# ### 拟合图

# plot_fit 函数绘制拟合值与所选自变量的关系。 它包括预测置信区间，并可以选择绘制真实因变量。

fig, ax = plt.subplots(figsize=(12, 8))
fig = sm.graphics.plot_fit(prestige_model, "education", ax=ax)

# ## 2009年全州犯罪数据集

# 与以下内容相比 http://www.ats.ucla.edu/stat/stata/webbooks/reg
# /chapter4/statareg_self_assessment_answers4.htm
#
# 尽管此处的数据与该示例中的数据不同。 您可以通过取消注释以下必要的单元格来运行该示例。

#dta = pd.read_csv("http://www.stat.ufl.edu/~aa/social/csv_files/statewide-
# crime-2.csv")
#dta = dta.set_index("State", inplace=True).dropna()
#dta.rename(columns={"VR" : "crime",
#                    "MR" : "murder",
#                    "M"  : "pctmetro",
#                    "W"  : "pctwhite",
#                    "H"  : "pcths",
#                    "P"  : "poverty",
#                    "S"  : "single"
#                    }, inplace=True)
#
#crime_model = ols("murder ~ pctmetro + poverty + pcths + single",
# data=dta).fit()

dta = sm.datasets.statecrime.load_pandas().data

crime_model = ols(
    "murder ~ urban + poverty + hs_grad + single", data=dta).fit()
print(crime_model.summary())

# ### 偏回归图

fig = plt.figure(figsize=(12, 8))
fig = sm.graphics.plot_partregress_grid(crime_model, fig=fig)

fig, ax = plt.subplots(figsize=(12, 8))
fig = sm.graphics.plot_partregress(
    "murder", "hs_grad", ["urban", "poverty", "single"], ax=ax, data=dta)

# ### 杠杆残差<sup>2</sup> 图

# 与 influence_plot 紧密相关的杠杆残差<sup>2</sup>图

fig, ax = plt.subplots(figsize=(8, 6))
fig = sm.graphics.plot_leverage_resid2(crime_model, ax=ax)

# ### 影响图

fig, ax = plt.subplots(figsize=(8, 6))
fig = sm.graphics.influence_plot(crime_model, ax=ax)

# ### 使用稳健的回归校正异常值。

# 在重新创建 Stata 结果时，部分问题在于 M 估计量不能稳健的处理杠杆点。 MM 估计器在这种情况的效果更好。

from statsmodels.formula.api import rlm

rob_crime_model = rlm(
    "murder ~ urban + poverty + hs_grad + single",
    data=dta,
    M=sm.robust.norms.TukeyBiweight(3)).fit(conv="weights")
print(rob_crime_model.summary())

#rob_crime_model = rlm("murder ~ pctmetro + poverty + pcths + single",
# data=dta, M=sm.robust.norms.TukeyBiweight()).fit(conv="weights")
#print(rob_crime_model.summary())

# 作为RLM的一部分，还没有影响诊断方法，但是我们可以重新构建。 (这取决于 [issue888](https://github.com/statsmodels/statsmodels/issues/808) 的状态)

weights = rob_crime_model.weights
idx = weights > 0
X = rob_crime_model.model.exog[idx.values]
ww = weights[idx] / weights[idx].mean()
hat_matrix_diag = ww * (X * np.linalg.pinv(X).T).sum(1)
resid = rob_crime_model.resid
resid2 = resid**2
resid2 /= resid2.sum()
nobs = int(idx.sum())
hm = hat_matrix_diag.mean()
rm = resid2.mean()

from statsmodels.graphics import utils
fig, ax = plt.subplots(figsize=(12, 8))
ax.plot(resid2[idx], hat_matrix_diag, 'o')
ax = utils.annotate_axes(
    range(nobs),
    labels=rob_crime_model.model.data.row_labels[idx],
    points=lzip(resid2[idx], hat_matrix_diag),
    offset_points=[(-5, 5)] * nobs,
    size="large",
    ax=ax)
ax.set_xlabel("resid2")
ax.set_ylabel("leverage")
ylim = ax.get_ylim()
ax.vlines(rm, *ylim)
xlim = ax.get_xlim()
ax.hlines(hm, *xlim)
ax.margins(0, 0)
