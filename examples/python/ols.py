# coding: utf-8

# DO NOT EDIT
# Autogenerated from the notebook ols.ipynb.
# Edit the notebook and then sync the output with this file.
#
# flake8: noqa
# DO NOT EDIT

# # 普通最小二乘法

import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
from statsmodels.sandbox.regression.predstd import wls_prediction_std

np.random.seed(9876789)

# ## OLS 估计
#
# 人工数据:

nsample = 100
x = np.linspace(0, 10, 100)
X = np.column_stack((x, x**2))
beta = np.array([1, 0.1, 10])
e = np.random.normal(size=nsample)

# 我们的模型需要一个截距，所以我们添加 1 列:

X = sm.add_constant(X)
y = np.dot(X, beta) + e

# Fit 和 summary:

model = sm.OLS(y, X)
results = model.fit()
print(results.summary())

# 有利的数量可以直接从拟合模型中提取。
# 输入 ``dir(results)`` 以获得完整列表。 这里有些例子：


print('Parameters: ', results.params)
print('R2: ', results.rsquared)

# ## OLS 非线性曲线但参数线性
#
# 我们在x和y之间模拟出非线性关系的人工数据：

nsample = 50
sig = 0.5
x = np.linspace(0, 20, nsample)
X = np.column_stack((x, np.sin(x), (x - 5)**2, np.ones(nsample)))
beta = [0.5, 0.5, -0.02, 5.]

y_true = np.dot(X, beta)
y = y_true + sig * np.random.normal(size=nsample)

# Fit 和 summary:

res = sm.OLS(y, X).fit()
print(res.summary())

# 提取其他有利的数量:

print('Parameters: ', res.params)
print('Standard errors: ', res.bse)
print('Predicted values: ', res.predict())

# 绘制一张来进行真实关系与 OLS 预测的比较。 使用 ``wls_prediction_std`` 命令建立预测的置信区间。


prstd, iv_l, iv_u = wls_prediction_std(res)

fig, ax = plt.subplots(figsize=(8, 6))

ax.plot(x, y, 'o', label="data")
ax.plot(x, y_true, 'b-', label="True")
ax.plot(x, res.fittedvalues, 'r--.', label="OLS")
ax.plot(x, iv_u, 'r--')
ax.plot(x, iv_l, 'r--')
ax.legend(loc='best')

# ## 带虚拟变量的 OLS
#
# 我们生成一些人工数据。使用虚拟变量对 3 个组进行建模。 组 0 是省略/基准类别。

nsample = 50
groups = np.zeros(nsample, int)
groups[20:40] = 1
groups[40:] = 2
#dummy = (groups[:,None] == np.unique(groups)).astype(float)

dummy = sm.categorical(groups, drop=True)
x = np.linspace(0, 20, nsample)
# 删除参考类别
X = np.column_stack((x, dummy[:, 1:]))
X = sm.add_constant(X, prepend=False)

beta = [1., 3, -3, 10]
y_true = np.dot(X, beta)
e = np.random.normal(size=nsample)
y = y_true + e

# 检查数据:

print(X[:5, :])
print(y[:5])
print(groups)
print(dummy[:5, :])

# Fit 和 summary:

res2 = sm.OLS(y, X).fit()
print(res2.summary())

# 绘制一张来进行真实关系与 OLS 预测的比较:

prstd, iv_l, iv_u = wls_prediction_std(res2)

fig, ax = plt.subplots(figsize=(8, 6))

ax.plot(x, y, 'o', label="Data")
ax.plot(x, y_true, 'b-', label="True")
ax.plot(x, res2.fittedvalues, 'r--.', label="Predicted")
ax.plot(x, iv_u, 'r--')
ax.plot(x, iv_l, 'r--')
legend = ax.legend(loc="best")

# ## 联合假设检验
#
# ### F 检验
#
# 我们要检验虚拟变量的两个系数都等于零的假设，即 $R \times \beta = 0$。 F 检验让我们直接的拒绝 3 个组是相同常数的零假设


R = [[0, 1, 0, 0], [0, 0, 1, 0]]
print(np.array(R))
print(res2.f_test(R))

# 您还可以使用类似于公式的语法来检验假设

print(res2.f_test("x2 = x3 = 0"))

# ### 小组效应
#
# 如果我们生成具有小组效应的人工数据，则 T 检验将无法拒绝零假设：

beta = [1., 0.3, -0.0, 10]
y_true = np.dot(X, beta)
y = y_true + np.random.normal(size=nsample)

res3 = sm.OLS(y, X).fit()

print(res3.f_test(R))

print(res3.f_test("x2 = x3 = 0"))

# ### 多重共线性
#
# 众所周知，Longley 数据集存在高度多重共线性。 即，外生预测变量高度相关。 这是有问题的，
# 因为当我们对模型进行细微改变时，它会影响系数估计的稳定性。


from statsmodels.datasets.longley import load_pandas
y = load_pandas().endog
X = load_pandas().exog
X = sm.add_constant(X)

# Fit 和 summary:

ols_model = sm.OLS(y, X)
ols_results = ols_model.fit()
print(ols_results.summary())

# #### Condition number
#
# 评估多重共线性的一种方法是计算条件数。超过 20 就存在问题（请参阅Greene 4.9）。 第一步是将自变量标准化为单位长度：


norm_x = X.values
for i, name in enumerate(X):
    if name == "const":
        continue
    norm_x[:, i] = X[name] / np.linalg.norm(X[name])
norm_xtx = np.dot(norm_x.T, norm_x)

# 然后，我们取最大特征值与最小特征值之比的平方根。

eigs = np.linalg.eigvals(norm_xtx)
condition_number = np.sqrt(eigs.max() / eigs.min())
print(condition_number)

# #### 剔除一个观测值
#
# Greene 指出，剔除单个观测值可能会对系数估计产生较大影响：


ols_results2 = sm.OLS(y.iloc[:14], X.iloc[:14]).fit()
print("Percentage change %4.2f%%\n" * 7 % tuple([
    i for i in
    (ols_results2.params - ols_results.params) / ols_results.params * 100
]))

# 我们可以考虑对 DFBETAS 的优等统计——一种忽视观测值的每个系数变化多少的标准化手段。


infl = ols_results.get_influence()

# 通常我们认为绝对值大于 $2/\sqrt{N}$ 的 DBETAS 时，对观测寄过是有影响的。

2. / len(X)**.5

print(infl.summary_frame().filter(regex="dfb"))
